Stopping times of [[Markov chains|Markov chains]] are random times you can tell have just occurred when observing the sequence $(X_{n})_{n\in\mathbb{N}}$, for example arriving at the cathedral, but the last step before arriving at the cathedral (if walking randomly) isn't a stopping time
## Definition
A [[Random Variables|random variable]] $T:\Omega\to \mathbb{N}_{0}\cup \left\{ \infty \right\}$ is a stopping time for $(X_{n})_{n\in\mathbb{N}_{0}}$ if $\left\{ T=k \right\}$ depends only on $X_{0},\dots,X_{k}$ for all $k\in\mathbb{N}_{0}$
In technical language, we require that 
$$
\left\{ \omega \in \Omega :\middle|: T(\omega)\leq k \right\}\in \sigma(X_{0},X_{1},\dots,X_{k})
$$
The [[Sigma Algebra|sigma algebra]] generated by $X_{0},\dots,X_{k}$
Stated in other wirds, $\left\{ \omega \in \Omega :\middle|: T(\omega)f\leq k \right\}$ can be written as the union of elementary events only involving $X_{0},\dots,X_{k}$ for all $k\geq 0$
## Example
The [[Hitting Times|hitting time]] $H^{A}$ is a stopping time as
$$
\left\{ H^{A}=n \right\}=\left\{ X_{0}\not\in  A,X_{1}\not\in  A,\dots X_{n-1}\not\in  A,X_{n}\in  A \right\}
$$
In particular, the first passage time to $j\in I$, $T_{j}=H^{\left\{ j \right\}}$ is a stopping time
## Remark
It depends on the particular Markov chain if a random variable is a stopping time or not
The Markov property says that, conditional on $\left\{ X_{n}=i \right\}$, the future $(X_{n+m})_{m\in\mathbb{N}_{0}}$ is $Markov(\delta_{i},P)$ and independent of the past
The [[strong Markov property|strong Markov property]] says that the same is true at stopping times
